{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonS3.html\n",
    "# https://boto3.readthedocs.io/en/latest/reference/services/s3.html#S3.Bucket.download_file\n",
    "# https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonS3.html\n",
    "# https://stackoverflow.com/questions/42090830/use-boto3-to-download-from-public-bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOWNLOADING DATA IN BULK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### USING WGET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "I was unable to get the Boto3 libarary to work.  It continually returned an access denied issue.  Using the python library awscli, I was able to install the AWS CLI on my server.  However, this did not alievate the problem.\n",
    "\n",
    "Then I tried an experiement wherein I used the https request to see if it might simply download whatever file was in the s3 bucket and save it to a file called export.zip.\n",
    "\n",
    "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonS3.html\n",
    "\n",
    "Instead, a file called index.html was successfully downloaded while the export.zip portion failed (I believe this is because wget does not take a filename to download to)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "wget https://dpla-provider-export.s3.amazonaws.com/ export.zip  \n",
    "\n",
    "--2018-06-25 16:31:47--  https://dpla-provider-export.s3.amazonaws.com/  \n",
    "Resolving dpla-provider-export.s3.amazonaws.com (dpla-provider-export.s3.amazonaws.com)... 52.216.160.3  \n",
    "Connecting to dpla-provider-export.s3.amazonaws.com (dpla-provider-export.s3.amazonaws.com)|52.216.160.3|:443... connected.  \n",
    "HTTP request sent, awaiting response... 200 OK  \n",
    "Length: unspecified [application/xml]  \n",
    "Saving to: `index.html'  \n",
    "\n",
    "    [ <=>                                                       ] 226,527 --.-K/s in 0.01s\n",
    "\n",
    "2018-06-25 16:31:47 (19.7 MB/s) - `index.html' saved [226527]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Having an index.html file was completely unexpected.  Upon expoloring the file, it became clear there was valid XML.  So I resaved the file as dpla_bucket.xml.  Opening this file in a browser did indeed show the XML not only for the entire json file, but for each individual provider json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "<ListBucketResult>\n",
    "    <Name>dpla-provider-export</Name>\n",
    "    <Prefix/>\n",
    "    <Marker/>\n",
    "    <MaxKeys>1000</MaxKeys>\n",
    "    <IsTruncated>true</IsTruncated>\n",
    "    <Contents>\n",
    "        <Key>2015/12/all.json.gz</Key>\n",
    "        <LastModified>2015-12-16T16:39:42.000Z</LastModified>\n",
    "        <ETag>\"7f5835017527b10b69e8156b632f2968-685\"</ETag>\n",
    "        <Size>5026500451</Size>\n",
    "        <StorageClass>STANDARD</StorageClass>\n",
    "    </Contents>\n",
    "    <Contents>\n",
    "        <Key>2015/12/artstor.json.gz</Key>\n",
    "        <AndSoOn></AndSoOn>\n",
    "    </Contents>\n",
    "    <AndSoOn></AndSoOn>\n",
    "<ListBucketResult>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "I was then able to use the following command to download any file listed in the \"Key\" attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "wget https://dpla-provider-export.s3.amazonaws.com/2015/12/all.json.gz\n",
    "\n",
    "--2018-06-25 16:36:55--  https://dpla-provider-export.s3.amazonaws.com/2015/12/all.json.gz  \n",
    "Resolving dpla-provider-export.s3.amazonaws.com (dpla-provider-export.s3.amazonaws.com)... 52.216.160.43  \n",
    "Connecting to dpla-provider-export.s3.amazonaws.com (dpla-provider export.s3.amazonaws.com)|52.216.160.43|:443... connected.  \n",
    "HTTP request sent, awaiting response... 200 OK  \n",
    "Length: 5026500451 (4.7G) [application/gzip]  \n",
    "Saving to: `all.json.gz'\n",
    "\n",
    "     100%[===============================================>] 5,026,500,451 48.8M/s in 1m 45s\n",
    "\n",
    "2018-06-25 16:38:40 (45.8 MB/s) - `all.json.gz' saved [5026500451/5026500451]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### USING AN AWS LIBRARY (DOES NOT WORK DUE TO DPLA PERMISSIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all set.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "\n",
    "print 'all set.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import boto3\n",
    "# import botocore\n",
    "\n",
    "# ACCESS_KEY = 'AWS_ACCESS_KEY'\n",
    "# SECRET_ACCESS_KEY = 'AWS_SECRET_ACCESS_KEY'\n",
    "# DPLA_BUCKET = 'dpla-provider-export'\n",
    "# FILE_KEY = '2015/12/georgia.json.gz'\n",
    "\n",
    "# # s3 = boto3.resource('s3')\n",
    "# s3 = boto3.resource('s3', aws_access_key_id=ACCESS_KEY, aws_secret_access_key= SECRET_ACCESS_KEY)\n",
    "# # bucket = s3.Bucket(DPLA_BUCKET)\n",
    "# # bucket.download_file(FILE_KEY, 'georgia.tar.gz')\n",
    "\n",
    "# try:\n",
    "#     s3.Bucket(DPLA_BUCKET).download_file(FILE_KEY, 'georgia.tar.gz')\n",
    "# except botocore.exceptions.ClientError as e:\n",
    "#     if e.response['Error']['Code'] == \"404\":\n",
    "#         print(\"The object does not exist.\")\n",
    "#     else:\n",
    "#         raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "s3_client = client = boto3.client('s3', aws_access_key_id=ACCESS_KEY, aws_secret_access_key= SECRET_ACCESS_KEY)\n",
    "s3_resource = boto3.resource('s3', aws_access_key_id=ACCESS_KEY, aws_secret_access_key= SECRET_ACCESS_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dpla-provider-export', None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket = s3.Bucket(DPLA_BUCKET)\n",
    "bucket.name, bucket.creation_date\n",
    "# bucket.get_available_subresources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dpla-provider-export', '2015/12/georgia.json.gz')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = s3_resource.Object(DPLA_BUCKET, FILE_KEY)\n",
    "obj.bucket_name, obj.key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPARING A FILE SAMPLE IN BASH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get count of lines and size of file:   \n",
    "  ```du -sh file.json # 1.6GB\n",
    "  wc -l file.json # 373085```  <br><br>\n",
    "2. Decide how much you in memory you have to spare.  In this case, my preference is for ~1/3rd.    \n",
    "```373085 - 2 (first and last lines are square brackets which we'll need to remove and then add back)  \n",
    "373083/3 = 124361```  <br><br>\n",
    "\n",
    "3. In order to get a random sample, we'll need to remove the brackets which are the [first and last lines](https://unix.stackexchange.com/questions/209068/how-do-i-delete-the-first-n-lines-and-last-line-of-a-file-using-shell-commands), else these lines would be a part of the random sample.  \n",
    "  ```sed '1d;$d' file.json.bk > file_no_brackets.json  \n",
    "  wc -l file_no_brackets.json # 373083```  <br><br> \n",
    "  \n",
    "4. Check to make sure it worked by [looking at the first N characters](https://stackoverflow.com/questions/14364397/read-first-8-characters-of-text-file-with-bash):  \n",
    "```head -c 100 file_no_brackets.json\n",
    "tail -c 100 file_no_brackets.json```<br><br>\n",
    "\n",
    "5. [Shuffle](https://stackoverflow.com/questions/9245638/select-random-lines-from-a-file-in-bash) 124361 lines and put them in a new file:  \n",
    "```shuf -n 124361 file_no_brackets.json > file_shuffled.json```<br><br>\n",
    "\n",
    "6. Check the head and tail again:    \n",
    "```head -c 100 file_shuffled.json\n",
    "tail -c 100 file_shuffled.json```<br><br>\n",
    "\n",
    "7. Unfortunately, the shuffle will probably cause a comma to be at the start and maybe the end so we must remove it.  Since it's right at the beginning I'll just do it by hand.  And while I'm at it, I'll replace it with a bracket [  and add a ] at the end as well.  [To get to the end of the file](https://stackoverflow.com/questions/17012308/move-cursor-to-end-of-file-in-vim), use :G$ then enter insert mode, or :GA to do both at the same time, then :wq. <br><br>\n",
    "\n",
    "8. To make sure it's valid json, copy and paste at least the first and last (I did two) line into a [json linter](https://jsonlint.com/).  You shouldn't have to add any comma's since each line actually begins with a comma.  If you are on a local computer, you can use pbcopy else it's good 'ol highlighting for you!  \n",
    "```head -n 1 file_shuffled.json\n",
    "tail -n 1 file_shuffled.json```<br><br>\n",
    "\n",
    "9. Now that it's validated, we can do a final check of the line count and file size.  Note, because of step 7, the file will still have the same number of lines.  As opposed to the original file in which the square brackets were each on their own line.  \n",
    "  ```du -sh file.json # 520MB\n",
    "  wc -l file.json # 124361```  <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DECIDING HOW LARGE TO MAKE THE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    124361 georgia_shuffled.json 520M\n",
    "    \n",
    "    100000 georgia_1e5.json      418M  80.40%  FAIL\n",
    "     50000 georgia_5e4.json      209M  40.20%  562M\n",
    "     25000 georgia_25e3.json     105M  20.10%  260M\n",
    "     12436 georgia_12e3.json      58M  10.00%   64M(?)   \n",
    "     10000 georgia_1e4.json       42M   8.04%   75M\n",
    "      5000 georgia_5e3.json       21M   4.02%   41M\n",
    "      2500 georgia_25e2.json      11M   2.01%   16M  \n",
    "      1000 georgia_1e3.json      6.1M   0.80%    3M\n",
    "       500 georgia_5e2.json      3.0M   0.40%    0M\n",
    "       250 georgia_25e1.json     1.5M   0.20%    0M \n",
    "\n",
    "    318611 total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING MEMORY CAPACITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HELPFUL LINKS:\n",
    "# 1. http://zetcode.com/python/simplejson/  \n",
    "\n",
    "import simplejson as json\n",
    "\n",
    "databases = 'data/databases/'\n",
    "state = 'georgia/'\n",
    "file_name = 'georgia_25e1.json'\n",
    "\n",
    "with open(databases + state + file_name) as json_file:\n",
    "    georgia = json.load(json_file)\n",
    "\n",
    "# print json.dumps(georgia[0], indent = 4 * ' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
