{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "FILE SIZE OPTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "    124361 georgia_shuffled.json 520M\n",
    "    \n",
    "    100000 georgia_1e5.json      418M  80.40%  FAIL\n",
    "     50000 georgia_5e4.json      209M  40.20%  562M\n",
    "     25000 georgia_25e3.json     105M  20.10%  260M\n",
    "     12436 georgia_12e3.json      58M  10.00%   64M(?)   \n",
    "     10000 georgia_1e4.json       42M   8.04%   75M\n",
    "      5000 georgia_5e3.json       21M   4.02%   41M\n",
    "      2500 georgia_25e2.json      11M   2.01%   16M  \n",
    "      1000 georgia_1e3.json      6.1M   0.80%    3M\n",
    "       500 georgia_5e2.json      3.0M   0.40%    0M\n",
    "       250 georgia_25e1.json     1.5M   0.20%    0M \n",
    "\n",
    "    318611 total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import simplejson as json\n",
    "import pprint\n",
    "from flatten_json import flatten\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### LOAD FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# # HELPFUL LINKS:\n",
    "# # 1. http://zetcode.com/python/simplejson/  \n",
    "\n",
    "\n",
    "databases = 'data/databases/'\n",
    "state = 'georgia/'\n",
    "file_name = 'georgia_25e1.json'\n",
    "\n",
    "with open(databases + state + file_name) as json_file:\n",
    "    georgia = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "county: True \tcountry: True \tstate: True \tname: True \tcoordinates: True \t"
     ]
    }
   ],
   "source": [
    "# # # SPATIAL\n",
    "# # {\"county\": \"Chatham County\", \"country\": \"United States\", \"state\": \"Georgia\", \n",
    "# #  \"name\": \"Savannah (Ga.)\",\"coordinates\": \"32.08354, -81.09983\"}\n",
    "\n",
    "# # # STATELOCATEDIN\n",
    "# # {\"name\": \"Athens, Ga. : Digital Library of Georgia\"}\n",
    "\n",
    "spatial_keys = ['county', 'country', 'state', 'name', 'coordinates']\n",
    "\n",
    "try:\n",
    "    spatial = georgia[5]['_source']['sourceResource']['spatial'][0]\n",
    "    \n",
    "    for spatial_key in spatial_keys:\n",
    "#         print spatial_key\n",
    "        \n",
    "        if spatial_key in spatial:\n",
    "            exists = True\n",
    "        else:\n",
    "            exists = False\n",
    "            \n",
    "        print spatial_key + ':', exists, '\\t',\n",
    "\n",
    "#     print_json(spatial, indent=2)\n",
    "\n",
    "except Exception as err:\n",
    "    \n",
    "    print err.__class__.__name__ + ' ' + str(err)\n",
    "#     print traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### SPATIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "spatial_keys = ['county', 'country', 'state', 'name', 'coordinates']\n",
    "\n",
    "for i, record in enumerate(georgia):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        sourceResource = record['_source']['sourceResource']\n",
    "        spatial = sourceResource['spatial'][0]\n",
    "        \n",
    "#         print str(i) + '.',\n",
    "        \n",
    "#         for spatial_key in spatial_keys:\n",
    "        \n",
    "#             if spatial_key in spatial:\n",
    "#                 exists = True\n",
    "#             else:\n",
    "#                 exists = False\n",
    "\n",
    "#             print spatial_key + ':', exists, '\\t',\n",
    "#         print ''\n",
    "        if spatial['coordinates']:\n",
    "            print str(i) +'.', spatial['coordinates']\n",
    "        \n",
    "    except Exception as err:\n",
    "        print str(i)+'.', err.__class__.__name__ + ': ' + str(err)\n",
    "#         count += 1\n",
    "\n",
    "# print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "NO SPATIAL INFORMATION: 15\n",
    "5. KeyError 'spatial'\n",
    "\n",
    "\n",
    "COUNTY: 207\n",
    "Name + County\n",
    "\n",
    "NO COUNTY: 28\n",
    "89. KeyError: 'county'\n",
    "    \n",
    "    \n",
    "COUNTRY:\n",
    "9. United States (231)\n",
    "10. Canada (1)\n",
    "    \n",
    "NO COUNTRY: 3\n",
    "119. KeyError: 'country'\n",
    "\n",
    "    \n",
    "STATE: 229\n",
    "0. Georgia: (223)\n",
    "10. Yukan (1)\n",
    "47. Mississippi (1)\n",
    "89. Florida (3)\n",
    "150. Ohio (1)\n",
    "\n",
    "NO STATE: 6\n",
    "240. KeyError: 'state'\n",
    "\n",
    "    \n",
    "NAME:\n",
    "0. Savannah (Ga.)\n",
    "2. Downtown, GA\n",
    "3. United States\n",
    "4. Georgia\n",
    "10. Dawson (Yukon)\n",
    "11. Gordon County (Ga.)\n",
    "45. Chicago (Ill.)\n",
    "47. Mississippi\n",
    "112. Houston Street (Atlanta, Ga.)\n",
    "119. Atlanta Metropolitan Area (Ga.)\n",
    "194. Dalton (Whitfield County, Ga.)\n",
    "\n",
    "NO NAME: 0\n",
    "\n",
    "\n",
    "COORDINATES:\n",
    "0. 32.08354, -81.09983\n",
    "\n",
    "NO COORDINATES: 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### STATE LOCATED IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for i, record in enumerate(georgia):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        sourceResource = record['_source']['sourceResource']\n",
    "        stateLocatedIn = sourceResource['stateLocatedIn'][0]\n",
    "\n",
    "        if not (':' in stateLocatedIn['name']):\n",
    "            print str(i) +'.', stateLocatedIn['name']\n",
    "#             count += 1\n",
    "    except Exception as err:\n",
    "        print str(i)+'.', err.__class__.__name__ + ': ' + str(err)\n",
    "#         count += 1\n",
    "\n",
    "# print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "STATE EXPLICIT: 200\n",
    "0. Athens, Ga. : Digital Library of Georgia\n",
    "6. Savannah (Ga.) : Asa H. Gordon Library in association with the Internet Archive\n",
    "47. Jackson (Miss.)] : Mississippi Dept. of Archives and History\n",
    "117. Athens, Ga.] : Digital Library of Georgia in association with the Troup County Archives\n",
    "174. Augusta (Ga.) : Reese Library in association with the Internet Archive\n",
    "\n",
    "STATE INFERRED: 34\n",
    "1. Georgia State University Library\n",
    "246. Special Collections and Archives, Georgia State University Library\n",
    "111. Kenan Research Center, Atlanta History Center, 130 West Paces Ferry Road, Atlanta, GA 30305\n",
    "\n",
    "LOCATION IS NOT A STATE: 5\n",
    "23. Knowledge Box\n",
    "79. New Georgia Encyclopedia\n",
    "94. Digital Library of Georgia\n",
    "\n",
    "NO HOLDING INFORMATION: 11\n",
    "5. KeyError 'stateLocatedIn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "georgia[0]['_source']['ingestionSequence']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### COUNTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIELDS MISSING: 250\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for i, record in enumerate(georgia):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        sourceResource = record['_source']['sourceResource']['physicalMedium']\n",
    "#         val = sourceResource['spatial'][0]['distance']\n",
    "        \n",
    "        print str(i) + '.', sourceResource, 'ID:', record['_source']['id']\n",
    "        \n",
    "#             count += 1\n",
    "    except Exception as err:\n",
    "#         print str(i)+'.', err.__class__.__name__ + ': ' + str(err)\n",
    "        count += 1\n",
    "\n",
    "print 'FIELDS MISSING:', count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AGGREGATE COUNTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "databases = 'data/databases/'\n",
    "state = 'georgia/'\n",
    "file_name = 'georgia_25e3.json'\n",
    "\n",
    "with open(databases + state + file_name) as json_file:\n",
    "    georgia = json.load(json_file)\n",
    "    \n",
    "\n",
    "# OVERALL SET COUNTERS\n",
    "sr_cntr = Counter()\n",
    "or_cntr = Counter()\n",
    "both_cntr = Counter()\n",
    "\n",
    "# SET OPERATIONS COUNTERS\n",
    "sr_not_or_cntr = Counter()\n",
    "or_not_sr_cntr = Counter()\n",
    "sr_and_or_cntr = Counter()\n",
    "\n",
    "metadata = []\n",
    "\n",
    "for record in georgia:\n",
    "    \n",
    "    totals = {}\n",
    "    \n",
    "    uid = record['_source']['id'] # OBTAIN UNIQUE ITEM ID\n",
    "    \n",
    "    # FLATTEN JSON\n",
    "    totals['sr_keys'] = flatten(georgia[0]['_source']['sourceResource']).keys()\n",
    "    totals['or_keys'] = flatten(georgia[0]['_source']['originalRecord']).keys()\n",
    "\n",
    "    # REMOVE _NUM AT END OF KEY AND REPLACE _NUM_ WITH _ AND PUT IN LISTS\n",
    "    totals['sr_list'] = [substitute_underscores(sr_key) for sr_key in totals['sr_keys']]\n",
    "    totals['or_list'] = [substitute_underscores(or_key) for or_key in totals['or_keys']]\n",
    "    totals['both_list'] = totals['sr_list'] + t['or_list']\n",
    "    \n",
    "    # REMOVE DUPLICATES AS A RESULT OF MULTIPLE IN AN ARRAY E.G. description_0, description_1, description_2...\n",
    "    totals['sr_set'] = set(sorted(totals['sr_list'])) #S\n",
    "    totals['or_set'] = set(sorted(totals['or_list'])) #T\n",
    "    totals['both_set'] = sr_set.union(totals['or_set']) #S & #T\n",
    "    \n",
    "    # SET OPERATIONS\n",
    "    totals['sr_not_or'] = sr_set.difference(totals['or_set']) # ELEMENTS IN SR_SET (S) BUT NOT IN OR_SET (T)\n",
    "    totals['or_not_sr'] = or_set.difference(totals['sr_set']) # ELEMENTS IN OR_SET (T) BUT NOT IN SR_SET (S)\n",
    "    totals['sr_and_or'] = sr_set.intersection(totals['or_set']) # ELEMENTS IN COMMON TO BOTH OR_SET (T) AND SR_SET (S)\n",
    "\n",
    "    metadatum = create_metadata_dict(uid, totals)\n",
    "    metadata.append(metadatum)\n",
    "    \n",
    "    # OVERALL SET COUNTERS\n",
    "    sr_cntr.update(totals['sr_set'])\n",
    "    or_cntr.update(totals['or_set'])\n",
    "    both_cntr.update(totals['both_set'])\n",
    "\n",
    "    # SET OPERATIONS COUNTERS\n",
    "    sr_not_or_cntr.update(totals['sr_not_or'])\n",
    "    or_not_sr_cntr.update(totals['or_not_sr'])\n",
    "    sr_and_or_cntr.update(totals['sr_and_or'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WRITE TO CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### UNIQUE ITEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers = ['uid', \\\n",
    "           'dpla_list', 'orig_list', 'both_list', \\\n",
    "           'dpla_set', 'orig_set', 'both_set', \\\n",
    "           'sr_not_or', 'or_not_sr', 'sr_and_or']\n",
    "\n",
    "\n",
    "with open('data/counts/metadata_by_uid.csv', 'w') as csv_file:\n",
    "\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for datum in metadata:\n",
    "    \n",
    "        metadata_dict = merge_dicts({'uid': datum['uid']}, datum['lists'], datum['sets'], datum['ops'])\n",
    "        writer.writerow(metadata_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COUNTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header = ['field', 'count']\n",
    "\n",
    "counters = [sr_cntr, or_cntr, both_cntr, sr_not_or_cntr, or_not_sr_cntr, sr_and_or_cntr]\n",
    "csv_filenames = ['sr_cntr', 'or_cntr', 'both_cntr', 'sr_not_or_cntr', 'or_not_sr_cntr', 'sr_and_or_cntr']\n",
    "\n",
    "for counter, csv_filename in zip(counters, csv_filenames):\n",
    "    \n",
    "    with open('data/counts/' + csv_filename + '.csv', 'w') as csv_file:\n",
    "        \n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(header)\n",
    "        \n",
    "        for key, val in counter.items():\n",
    "            writer.writerow([key] + [val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_json(json_obj, skipkeys=False, indent=2, sort_keys=False):\n",
    "    \n",
    "    print json.dumps(json_obj, skipkeys=skipkeys, indent=indent, sort_keys=sort_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def substitute_underscores(key):\n",
    "    \n",
    "    last_num = re.compile(r'_\\d$')\n",
    "    middle_num = re.compile(r'_\\d_')\n",
    "    \n",
    "    key = re.sub(last_num, '', key)\n",
    "    key = re.sub(middle_num, '_', key)\n",
    "    \n",
    "    return key\n",
    "\n",
    "# [substitute_underscores(key) for key in sr_sort]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_metadata_dict(uid, totals):\n",
    "     \n",
    "    datum = {'lists': {}, 'sets': {}, 'ops': {}}\n",
    "    \n",
    "    datum['uid'] = str(uid)\n",
    "    \n",
    "    datum['lists']['dpla_list'] = len(t['sr_list'])\n",
    "    datum['lists']['orig_list'] = len(t['or_list'])\n",
    "    datum['lists']['both_list'] = len(t['both_list'])\n",
    "    \n",
    "    datum['sets']['dpla_set'] = len(t['sr_set'])\n",
    "    datum['sets']['orig_set'] = len(t['or_set'])\n",
    "    datum['sets']['both_set'] = len(t['both_set'])\n",
    "    \n",
    "    datum['ops']['sr_not_or'] = len(t['sr_not_or'])\n",
    "    datum['ops']['or_not_sr'] = len(t['or_not_sr'])\n",
    "    datum['ops']['sr_and_or'] = len(t['sr_and_or'])\n",
    "    \n",
    "    return datum\n",
    "\n",
    "# create_metadata_dict('a45aewv35789w', t) # t was made below, see testing\n",
    "# # {'lists': {'both_list': 59,...}, 'ops': {'or_not_sr': 13,...}, 'sets': {'both_set': 32,...}, 'uid': 'a45aewv35789w'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/26853961/6023530\n",
    "\n",
    "def merge_dicts(*dict_args):\n",
    "    \"\"\"\n",
    "    Given any number of dicts, shallow copy and merge into a new dict,\n",
    "    precedence goes to key value pairs in latter dicts.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for dictionary in dict_args:\n",
    "        result.update(dictionary)\n",
    "    return result\n",
    "\n",
    "# d1 = {'sets': {'test1': 1, 'test2': 2}}\n",
    "# d2 = {'sets': {'test4': 4, 'test5': 5}}\n",
    "# d3 = {'sets': {'test7': 7, 'test8': 8}}\n",
    "# merge_dicts(d1['sets'], d2['sets'], d3['sets'])\n",
    "# # {'test1': 1, 'test2': 2, 'test4': 4, 'test5': 5, 'test7': 7, 'test8': 8}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPLA: \tLIST: 23 \tSET: 19 \tNOT IN OR: 11\n",
      "ORIG: \tLIST: 36 \tSET: 21 \tNOT IN SR: 13\n",
      "BOTH: \tLIST: 59 \tSET: 32 \tSR AND OR: 8\n"
     ]
    }
   ],
   "source": [
    "# json.dumps(flatten(georgia[0]['_source']['originalRecord']))\n",
    "# json.dumps(flatten(georgia[0]['_source']['sourceResource']))\n",
    "\n",
    "t = {}\n",
    "\n",
    "t['sr_keys'] = flatten(georgia[0]['_source']['sourceResource']).keys()\n",
    "t['or_keys'] = flatten(georgia[0]['_source']['originalRecord']).keys()\n",
    "\n",
    "t['sr_list'] = [substitute_underscores(sr_key) for sr_key in t['sr_keys']]\n",
    "t['or_list'] = [substitute_underscores(or_key) for or_key in t['or_keys']]\n",
    "t['both_list'] = t['sr_list'] + t['or_list']\n",
    "\n",
    "t['sr_set'] = set(sorted(t['sr_list'])) #S\n",
    "t['or_set'] = set(sorted(t['or_list'])) #T\n",
    "t['both_set'] = sr_set.union(t['or_set']) #S & #T\n",
    "\n",
    "# ELEMENTS IN SR_SET (S) BUT NOT IN OR_SET (T)\n",
    "t['sr_not_or'] = sr_set.difference(t['or_set'])\n",
    "\n",
    "# ELEMENTS IN OR_SET (T) BUT NOT IN SR_SET (S)\n",
    "t['or_not_sr'] = or_set.difference(t['sr_set'])\n",
    "\n",
    "t['sr_and_or'] = sr_set.intersection(t['or_set'])\n",
    "\n",
    "print 'DPLA:', '\\tLIST:', len(t['sr_list']), '\\tSET:', len(t['sr_set']), '\\tNOT IN OR:', len(t['sr_not_or'])\n",
    "print 'ORIG:', '\\tLIST:', len(t['or_list']), '\\tSET:', len(t['or_set']), '\\tNOT IN SR:', len(t['or_not_sr'])\n",
    "print 'BOTH:', '\\tLIST:', len(t['both_list']), '\\tSET:', len(t['both_set']), '\\tSR AND OR:', len(t['sr_and_or']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR NOT OR: ['date_begin', 'date_displayDate', '@id', 'date_end', 'spatial_county', 'subject_name', 'stateLocatedIn_name', 'spatial_coordinates', 'spatial_name', 'spatial_state', 'spatial_country']\n",
      "\n",
      "OR NOT SR: ['publisher', 'handle', 'format', 'contributor', 'label', 'date', 'coverage', 'datestamp', 'provider_@id', 'provider_name', 'id', 'setSpec', 'subject']\n",
      "\n",
      "BOTH: ['description', 'title', 'collection_description', 'rights', 'collection_@id', 'collection_title', 'collection_id', 'type']\n"
     ]
    }
   ],
   "source": [
    "print 'SR NOT OR:', list(sr_not_or)\n",
    "print ''\n",
    "print 'OR NOT SR:', list(or_not_sr)\n",
    "print ''\n",
    "print 'BOTH:', list(sr_and_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/a/43359722/6023530\n",
    "\n",
    "# def get_nested_keys(dict_or_list, path=[]):\n",
    "#     if isinstance(dict_or_list, dict):\n",
    "#         iterator = dict_or_list.iteritems()\n",
    "#     else:\n",
    "#         iterator = enumerate(dict_or_list)\n",
    "#     for k, v in iterator:\n",
    "#         yield path + [k], v\n",
    "#         if isinstance(v, (dict, list)):\n",
    "#             for k, v in traverse(v, path + [k]):\n",
    "#                 yield k, v\n",
    "\n",
    "# keys = []\n",
    "\n",
    "# for path, node in get_nested_keys(georgia[0]['_source']['sourceResource']):\n",
    "#     print path\n",
    "# #     keys += path\n",
    "    \n",
    "# print keys\n",
    "\n",
    "# sr_nested_keys= get_nested_keys(georgia[0]['_source']['sourceResource'])\n",
    "# or_nested_keys = get_nested_keys(georgia[0]['_source']['originalRecord'])\n",
    "\n",
    "# # ELEMENTS IN SR_SET (S) BUT NOT IN OR_SET (T)\n",
    "# sr_not_or = sr_nested_keys.difference(or_nested_keys)\n",
    "\n",
    "# # ELEMENTS IN OR_SET (T) BUT NOT IN SR_SET (S)\n",
    "# or_not_sr = or_nested_keys.difference(sr_nested_keys)\n",
    "\n",
    "# both = sr_nested_keys.intersection(or_nested_keys)\n",
    "\n",
    "# sr_nested_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print_json(georgia[0]['_source']['sourceResource'], indent=4, sort_keys=False)\n",
    "# print_json(georgia[0]['_source']['originalRecord'], indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MISSING FIELDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# MISSING FIELDS\n",
    "\n",
    "# CONTRIBUTOR (DC): 250\n",
    "# EXTENT (DC): 250\n",
    "# PHYSICAL MEDIUM (DC): 250\n",
    "# PUBLISHER (DC): 250\n",
    "# TEMPORAL (DPLA): 250\n",
    "# INTERMEDIATE PROVIDER (DPLA): 250\n",
    "# SPATIAL DISTANCE (DPLA): 250\n",
    "# SPATIAL REGION (DPLA): 250\n",
    "    \n",
    "# NOT YET IN DATABASE\n",
    "# SUBJECT ID\n",
    "# SUBJECT TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUESTIONS\n",
    "\n",
    "1. What MAP does the current bulk download adhere to?\n",
    "2. Why are certain fields renamed, i.e. edm:Place is now spatial.\n",
    "3. Where are all of the other MAP fields?  Not required?  Not used yet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LINKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonS3.html\n",
    "# https://boto3.readthedocs.io/en/latest/reference/services/s3.html#S3.Bucket.download_file\n",
    "# https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonS3.html\n",
    "# https://stackoverflow.com/questions/42090830/use-boto3-to-download-from-public-bucket\n",
    "# https://raw.githubusercontent.com/dpla/schema/master/dpla_map_3.owl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
